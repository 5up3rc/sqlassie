/*
 * SQLassie - database firewall
 * Copyright (C) 2011 Brandon Skari <brandon.skari@gmail.com>
 *
 * This file is part of SQLassie.
 *
 * SQLassie is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * SQLassie is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with SQLassie. If not, see <http://www.gnu.org/licenses/>.
 */

// This needs to be defined prior to including the scanner header
#define YY_DECL int sql_lex( \
    ScannerContext* const context, \
    yyscan_t yyscanner \
)

#include "clearStack.hpp"
#include "nullptr.hpp"
#include "sqlParser.h"
#include "ParserInterface.hpp"
#include "scanner.yy.hpp"
#include "ScannerContext.hpp"
#include "TokenInfo.hpp"

#include <cassert>
#include <boost/shared_ptr.hpp>
#include <exception>
#include <string>
#include <vector>

using boost::shared_ptr;
using std::bad_alloc;
using std::size_t;
using std::string;
using std::vector;

// Methods from the parser
extern void* sqlassieParseAlloc(void* (*allocProc)(size_t numBytes));
extern void* sqlassieParse(
    void* parser,
    int token,
    TokenInfo* ti_,
    ScannerContext* qrPtr
);
extern void* sqlassieParseFree(void* parser, void(*freeProc)(void* ptr));
// Methods from the scanner
extern YY_DECL;

/**
 * Hide some scanner members behind a PIMPL so that I don't have to worry
 * about dependency issues in my Makefile. Long explanation: I'm using a
 * script to update my Makefile dependencies. I used to include
 * scanner.yy.hpp, the header file generated by Flex, in ParserInterface's
 * header file. However, my script only looks at cpp dependencies because
 * it assumes that header files are static and not dynamically generated,
 * which works just fine for the other 99% of my files but doesn't work for
 * Flex. Anyway, I'm just going to hide the scanner's members here so that I
 * can break that nasty dependency.
 */
class ParserInterfaceScannerMembers
{
public:
    explicit ParserInterfaceScannerMembers(const char* const query);
    ~ParserInterfaceScannerMembers();
    yyscan_t scanner_;
    YY_BUFFER_STATE bufferState_;
private:
    ParserInterfaceScannerMembers(const ParserInterfaceScannerMembers&);
    ParserInterfaceScannerMembers& operator=(
        const ParserInterfaceScannerMembers&
    );
};


ParserInterface::ParserInterface(const string& buffer)
    : qr_()
    , scannerContext_(&qr_)
    , scannerPimpl_(new ParserInterfaceScannerMembers(buffer.c_str()))
    , tokensHash_()
    , parsed_(false)
    , successfullyParsed_(false)
    , bufferLen_(buffer.size())
    , lemonParser_(sqlassieParseAlloc(malloc))
{
    if (nullptr == lemonParser_)
    {
        delete scannerPimpl_;
        throw bad_alloc();
    }
}


ParserInterface::~ParserInterface()
{
    delete scannerPimpl_;
    sqlassieParseFree(lemonParser_, free);
}


bool ParserInterface::parse(QueryRisk* const qrPtr)
{
    assert(NULL != qrPtr);
    if (parsed_)
    {
        *qrPtr = qr_;
        return successfullyParsed_;
    }

    int lexToken;
    vector<shared_ptr<TokenInfo> > tokenInfos;
    do
    {
        shared_ptr<TokenInfo> ti(new TokenInfo);
        lexToken = getLexValue(ti.get());
        // We want to keep reading all of the tokens even if parsing has
        // failed, but don't try to keep parsing
        if (qr_.valid)
        {
            // Save the TokenInfo so that it can be used by the parser
            tokenInfos.push_back(ti);

            sqlassieParse(
                lemonParser_,
                lexToken,
                ti.get(),
                &scannerContext_
            );
        }
    }
    while (lexToken != 0);

    *qrPtr = qr_;
    successfullyParsed_ = qr_.valid;
    parsed_ = true;

    // If the parser failed, we still need to manually calculate the rest of
    // the hash for this query. That calculation is handled in getLexValue, so
    // just keep calling that ourselves until it hits the end of the buffer.
    if (!successfullyParsed_)
    {
        TokenInfo dummyTokenInfo;
        const int END_OF_TOKENS = 0;
        while (getLexValue(&dummyTokenInfo) != END_OF_TOKENS);
    }

    return successfullyParsed_;
}


ParserInterface::QueryHash ParserInterface::getHash() const
{
    assert(parsed_ && "gethash() called before parse(QueryRisk* const)");
    return tokensHash_;
}


ParserInterface::QueryHash::QueryHash() :
    hash(0),
    tokensCount(0)
{
}


bool operator==(
    const ParserInterface::QueryHash& hash1,
    const ParserInterface::QueryHash& hash2
)
{
    return hash1.hash == hash2.hash
        && hash1.tokensCount == hash2.tokensCount;
}


size_t hash_value(const ParserInterface::QueryHash& qh)
{
    return static_cast<size_t>(qh.hash + qh.tokensCount);
}


ParserInterfaceScannerMembers::ParserInterfaceScannerMembers(
    const char* const query
) :
    scanner_(),
    bufferState_(nullptr)
{
    if (0 != sql_lex_init(&scanner_))
    {
        throw bad_alloc();
    }
    bufferState_ = sql__scan_string(query, scanner_);
    if (nullptr == bufferState_)
    {
        sql_lex_destroy(scanner_);
        throw bad_alloc();
    }
}


ParserInterfaceScannerMembers::~ParserInterfaceScannerMembers()
{
    sql__delete_buffer(bufferState_, scanner_);
    sql_lex_destroy(scanner_);
}


/**
 * Calculates the partial sdbm hash, given a new lexeme.
 * @param lexCode The new lexeme from the buffer stream.
 * @param ht The previous hash.
 */
static ParserInterface::hashType sdbmHash(
    const int lexCode,
    const ParserInterface::hashType ht
);


int ParserInterface::getLexValue(TokenInfo* const ti)
{
    assert(nullptr != ti);

    const int lexCode = sql_lex(
        &scannerContext_,
        scannerPimpl_->scanner_
    );
    // Don't calculate the hash anymore once we've hit the end of the buffer.
    // Queries that have a bunch of semicolons at the end are considered to be
    // the same too, so don't hash them.
    const int END_OF_BUFFER = 0;
    if (END_OF_BUFFER != lexCode && SEMI != lexCode)
    {
        ++tokensHash_.tokensCount;
        tokensHash_.hash = sdbmHash(lexCode, tokensHash_.hash);

        // There's a big difference between, for example,
        // SELECT * FROM email WHERE address = 'brandon@aol.com' AND active = 1
        // SELECT * FROM order WHERE description = 'software' AND count = 1
        // even though the lexeme streams are the same. To differentiate them,
        // also hash the table and column names.
        if (lexCode == ID)
        {
            const char* id = sql_get_text(scannerPimpl_->scanner_);
            while ('\0' != *id)
            {
                tokensHash_.hash = sdbmHash(*id, tokensHash_.hash);
                ++id;
            }
        }
    }

    // Set the TokenInfo
    string id(sql_get_text(scannerPimpl_->scanner_));
    switch (lexCode)
    {
        // ID can be a quoted string, which we trim
        case ID:
            if ('`' == id.at(0))
            {
                ti->scannedString_ = id.substr(1, id.length() - 2);
                break;
            }
        // Everything else (including regular IDs) just get set normally
        default:
            ti->scannedString_ = string(sql_get_text(scannerPimpl_->scanner_));;
            break;
    }
    ti->token_ = lexCode;

    return lexCode;
}


static ParserInterface::hashType sdbmHash(
    const int lexCode,
    const ParserInterface::hashType ht
)
{
    return lexCode + (ht << 6) + (ht << 16) - ht;
}
